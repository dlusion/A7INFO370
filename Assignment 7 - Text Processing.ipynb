{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 - Text Processing (Group)\n",
    "*Daniel Lu, Wanyu Guan, Markus Shriner*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the data. You may drop size, lines, and pagenr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>\\nTitle: Early Lives of Charlemagne by Eginhar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>\\n\\nThe notes, keyed to line numbers in the so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>\\n         From a bronze statuette in the Musé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>\\n                _A lui finit la dissolution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>public opinion in regard to the meaning of fal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "0  balbulus-early-life-charlemagne   \n",
       "1  balbulus-early-life-charlemagne   \n",
       "2  balbulus-early-life-charlemagne   \n",
       "3  balbulus-early-life-charlemagne   \n",
       "4  balbulus-early-life-charlemagne   \n",
       "\n",
       "                                                text  \n",
       "0  \\nTitle: Early Lives of Charlemagne by Eginhar...  \n",
       "1  \\n\\nThe notes, keyed to line numbers in the so...  \n",
       "2  \\n         From a bronze statuette in the Musé...  \n",
       "3  \\n                _A lui finit la dissolution ...  \n",
       "4  public opinion in regard to the meaning of fal...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data \n",
    "tx = pd.read_csv(\"./texts.csv.bz2\", sep=\"\\t\")\n",
    "tx.drop(columns=[\"size\", \"lines\", \"pagenr\"], inplace=True)\n",
    "tx.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ensure that you don't have any missing name, and empty text in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name    0\n",
       "text    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name    0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create a summary table where you show how many chunks of each book you have in data. Order this by size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>cia-world-factbook-1992</td>\n",
       "      <td>2822</td>\n",
       "      <td>2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bible</td>\n",
       "      <td>1321</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>webster-early-european-history</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vaneeden-quest</td>\n",
       "      <td>864</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hardy-madding-crowd</td>\n",
       "      <td>723</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>why-speech-output</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>selected-polish-tales</td>\n",
       "      <td>534</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unamuno-tragic-sense-of-life</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>naval-academy-sound-military-decision</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>milton-paradise-lost</td>\n",
       "      <td>466</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eckstein-quintus-claudius</td>\n",
       "      <td>445</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>newsgroup</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>workshop-proceedings</td>\n",
       "      <td>327</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gordon-quiet-talks-crowned-christ</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>beesly-queen-elizabeth</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gallienne-quest-of-golden-girl</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fisher-quaker-colonies</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shakespeare-as-you-like-it</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>carroll-alice-wonderland</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>karn-snowflakes</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>infiltrating-open-systems</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kant-metaphysical-elements-ethics</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chipman-earliest-electromagnetic-instruments</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paper-data-compression</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paper-search-for-autonomy</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paper-compact-hash-tables</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paper-logical-implementation-of-arithmetic</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paper-programming-by-example</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  tokens\n",
       "name                                                      \n",
       "cia-world-factbook-1992                       2822    2822\n",
       "bible                                         1321    1321\n",
       "webster-early-european-history                1265    1265\n",
       "vaneeden-quest                                 864     864\n",
       "hardy-madding-crowd                            723     723\n",
       "why-speech-output                              680     680\n",
       "selected-polish-tales                          534     534\n",
       "unamuno-tragic-sense-of-life                   519     519\n",
       "naval-academy-sound-military-decision          485     485\n",
       "milton-paradise-lost                           466     466\n",
       "eckstein-quintus-claudius                      445     445\n",
       "newsgroup                                      438     438\n",
       "workshop-proceedings                           327     327\n",
       "gordon-quiet-talks-crowned-christ              291     291\n",
       "beesly-queen-elizabeth                         285     285\n",
       "gallienne-quest-of-golden-girl                 261     261\n",
       "fisher-quaker-colonies                         197     197\n",
       "balbulus-early-life-charlemagne                192     192\n",
       "shakespeare-as-you-like-it                     180     180\n",
       "carroll-alice-wonderland                       157     157\n",
       "karn-snowflakes                                 88      88\n",
       "infiltrating-open-systems                       76      76\n",
       "kant-metaphysical-elements-ethics               72      72\n",
       "chipman-earliest-electromagnetic-instruments    60      60\n",
       "paper-data-compression                          55      55\n",
       "paper-search-for-autonomy                       48      48\n",
       "paper-compact-hash-tables                       45      45\n",
       "paper-logical-implementation-of-arithmetic      14      14\n",
       "paper-programming-by-example                    13      13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.groupby('name').count().sort_values(by='text', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Explore the data: check out a few pages from various titles, as a minimum take a look how do a few books and a few CS papers look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First Task: Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Convert all texts to lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\ntitle: early lives of charlemagne by eginhar...\n",
       "1        \\n\\nthe notes, keyed to line numbers in the so...\n",
       "2        \\n         from a bronze statuette in the musé...\n",
       "3        \\n                _a lui finit la dissolution ...\n",
       "4        public opinion in regard to the meaning of fal...\n",
       "                               ...                        \n",
       "12919         descriptive cataloging division lm 540\\n ...\n",
       "12920         james graber\\n     information technology...\n",
       "12921    \\n     john w. kimball, jr\\n     machine-reada...\n",
       "12922         (202) 707-7706\\n\\n     chandru j. shahani...\n",
       "12923         preservation microfilming office lm g05\\n...\n",
       "Name: text, Length: 12923, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.text = tx.text.str.lower()\n",
    "tx.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remove punctuation and other weird characters. I recommend to replace these with space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx.text = tx.text.map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "tx.text = tx.text.map(lambda x: re.sub('[^a-z0-9]+', ' ', x))\n",
    "# tx.text.map(lambda x: print('$$$' + x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punk = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "# punk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx.text = tx.text.str.translate(str.maketrans(punk, ' '*len(punk))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         title early lives of charlemagne by eginhard ...\n",
       "1         the notes keyed to line numbers in the source...\n",
       "2         from a bronze statuette in the mus e carnaval...\n",
       "3         a lui finit la dissolution de l ancien monde ...\n",
       "4        public opinion in regard to the meaning of fal...\n",
       "                               ...                        \n",
       "12919     descriptive cataloging division lm 540 202 70...\n",
       "12920     james graber information technology services ...\n",
       "12921     john w kimball jr machine readable collection...\n",
       "12922     202 707 7706 chandru j shahani preservation r...\n",
       "12923     preservation microfilming office lm g05 202 7...\n",
       "Name: text, Length: 12923, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tokenize texts to words. If you replaced punctuation with spaces, you can just use pandas' str.split method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx['tokens'] = tx.text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [title, early, lives, of, charlemagne, by, egi...\n",
       "1        [the, notes, keyed, to, line, numbers, in, the...\n",
       "2        [from, a, bronze, statuette, in, the, mus, e, ...\n",
       "3        [a, lui, finit, la, dissolution, de, l, ancien...\n",
       "4        [public, opinion, in, regard, to, the, meaning...\n",
       "                               ...                        \n",
       "12919    [descriptive, cataloging, division, lm, 540, 2...\n",
       "12920    [james, graber, information, technology, servi...\n",
       "12921    [john, w, kimball, jr, machine, readable, coll...\n",
       "12922    [202, 707, 7706, chandru, j, shahani, preserva...\n",
       "12923    [preservation, microfilming, office, lm, g05, ...\n",
       "Name: tokens, Length: 12923, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Remove stopwords. It is up to you to decide which stopwords to remove, I recommend to include at least the and a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>title early lives of charlemagne by eginhard ...</td>\n",
       "      <td>[title, early, lives, charlemagne, eginhard, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>the notes keyed to line numbers in the source...</td>\n",
       "      <td>[notes, keyed, line, numbers, source, edition,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>from a bronze statuette in the mus e carnaval...</td>\n",
       "      <td>[bronze, statuette, mus, e, carnavalet, paris,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>a lui finit la dissolution de l ancien monde ...</td>\n",
       "      <td>[lui, finit, la, dissolution, de, l, ancien, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>balbulus-early-life-charlemagne</td>\n",
       "      <td>public opinion in regard to the meaning of fal...</td>\n",
       "      <td>[public, opinion, regard, meaning, falsehood, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "0  balbulus-early-life-charlemagne   \n",
       "1  balbulus-early-life-charlemagne   \n",
       "2  balbulus-early-life-charlemagne   \n",
       "3  balbulus-early-life-charlemagne   \n",
       "4  balbulus-early-life-charlemagne   \n",
       "\n",
       "                                                text  \\\n",
       "0   title early lives of charlemagne by eginhard ...   \n",
       "1   the notes keyed to line numbers in the source...   \n",
       "2   from a bronze statuette in the mus e carnaval...   \n",
       "3   a lui finit la dissolution de l ancien monde ...   \n",
       "4  public opinion in regard to the meaning of fal...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [title, early, lives, charlemagne, eginhard, m...  \n",
       "1  [notes, keyed, line, numbers, source, edition,...  \n",
       "2  [bronze, statuette, mus, e, carnavalet, paris,...  \n",
       "3  [lui, finit, la, dissolution, de, l, ancien, m...  \n",
       "4  [public, opinion, regard, meaning, falsehood, ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once',\n",
    "                  'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for',\n",
    "                  'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is',\n",
    "                  's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until',\n",
    "                  'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were',\n",
    "                  'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above',\n",
    "                  'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before',\n",
    "                  'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then',\n",
    "                  'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he',\n",
    "                  'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i',\n",
    "                  'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing',\n",
    "                  'it', 'how', 'further', 'was', 'here', 'than', '\\x1a']\n",
    "\n",
    "tx.tokens = tx['tokens'].apply(lambda x: [token for token in x if token not in stop_words])\n",
    "tx.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create such vocabulary and order it alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for i in range(len(tx.tokens)):\n",
    "    vocab|=set(tx.tokens.iat[i])\n",
    "# vocab |= set(tx.text.iat[i] for i in range(len(tx.text)))\n",
    "vocab = sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '00000000000test',\n",
       " '00006',\n",
       " '0001',\n",
       " '0002',\n",
       " '00021']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>00000000000test</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002</th>\n",
       "      <th>00021</th>\n",
       "      <th>00021053</th>\n",
       "      <th>...</th>\n",
       "      <th>zurbuchen</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zuriel</th>\n",
       "      <th>zurishaddai</th>\n",
       "      <th>zuta</th>\n",
       "      <th>zuzims</th>\n",
       "      <th>zviad</th>\n",
       "      <th>zwingli</th>\n",
       "      <th>zx</th>\n",
       "      <th>zzassgl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12923 rows × 63352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  0000  00000  00000000000test  00006  0001  0002  00021  \\\n",
       "0       0    0     0      0                0      0     0     0      0   \n",
       "1       0    0     0      0                0      0     0     0      0   \n",
       "2       0    0     0      0                0      0     0     0      0   \n",
       "3       0    0     0      0                0      0     0     0      0   \n",
       "4       0    0     0      0                0      0     0     0      0   \n",
       "...    ..  ...   ...    ...              ...    ...   ...   ...    ...   \n",
       "12918   0    0     0      0                0      0     0     0      0   \n",
       "12919   0    0     0      0                0      0     0     0      0   \n",
       "12920   0    0     0      0                0      0     0     0      0   \n",
       "12921   0    0     0      0                0      0     0     0      0   \n",
       "12922   0    0     0      0                0      0     0     0      0   \n",
       "\n",
       "       00021053  ...  zurbuchen  zurich  zuriel  zurishaddai  zuta  zuzims  \\\n",
       "0             0  ...          0       0       0            0     0       0   \n",
       "1             0  ...          0       0       0            0     0       0   \n",
       "2             0  ...          0       0       0            0     0       0   \n",
       "3             0  ...          0       0       0            0     0       0   \n",
       "4             0  ...          0       0       0            0     0       0   \n",
       "...         ...  ...        ...     ...     ...          ...   ...     ...   \n",
       "12918         0  ...          0       0       0            0     0       0   \n",
       "12919         0  ...          0       0       0            0     0       0   \n",
       "12920         0  ...          0       0       0            0     0       0   \n",
       "12921         0  ...          0       0       0            0     0       0   \n",
       "12922         0  ...          0       0       0            0     0       0   \n",
       "\n",
       "       zviad  zwingli  zx  zzassgl  \n",
       "0          0        0   0        0  \n",
       "1          0        0   0        0  \n",
       "2          0        0   0        0  \n",
       "3          0        0   0        0  \n",
       "4          0        0   0        0  \n",
       "...      ...      ...  ..      ...  \n",
       "12918      0        0   0        0  \n",
       "12919      0        0   0        0  \n",
       "12920      0        0   0        0  \n",
       "12921      0        0   0        0  \n",
       "12922      0        0   0        0  \n",
       "\n",
       "[12923 rows x 63352 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrizer = CountVectorizer()\n",
    "r = vrizer.fit(tx.text) \n",
    "X = vrizer.transform(tx.text)\n",
    "pd.DataFrame(X.toarray(), columns= vrizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
